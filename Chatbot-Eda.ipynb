{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e97b6406-8e7f-4b76-ba4c-41594bbded81",
   "metadata": {},
   "source": [
    "# CONSTRUCCIÓN DE UN ASISTENTE CHATBOT  PQRS\n",
    "\n",
    "Fecha: 30/11/2024\n",
    "### Integrantes\n",
    "\n",
    "- Jose Manuel Villa Romero\n",
    "- Sebastian Vasquez Grajales\n",
    "\n",
    "consiste en construir un sistema de transformacion de frases y cadenas textuales en conjuntos de palabras faciles de interpretar por el modelo de machine learning haciendo uso de tecnicas gramaticales para limpiar, simplificar, dividir, clasificar y reducir terminos para luego usarlos como patrones de aprendizaje. el enfoque que se busca con este ejercicio es aplicar el proceso de tratamiento y transformacion a un conjunto de frases provenientes de un set de datos de reseñas, comentarios y opiniones, y con base a ello generar una bolsa de palabras a partir de las palabras que componen dichas frases. el flujo de trabajo es el siguiente:\n",
    "\n",
    "- **1.** Generacion del algoritmo de tratamiento de datos y representacion para:\n",
    "     - Tokenización\n",
    "     - Limpieza\n",
    "     - Eliminación de stopwords\n",
    "     - Lematización\n",
    "     - Stemming (si aplica)\n",
    "     - Bag of words\n",
    "- **2.** Clasificación del conjunto de etiquetas, y construcción del dataframe con:\n",
    "     -  Saludo\n",
    "     -  Queja\n",
    "     -  Reclamo\n",
    "     -  Petición\n",
    "     -  Despedida\n",
    "     -  Información de contacto\n",
    "     -  Horario de atención\n",
    "     -  Precios\n",
    "     -  Política de devolución\n",
    "     -  Soporte técnico\n",
    "- **3.** Diseño de modelo de machine learning\n",
    "     - Entrenamiento de Naive Bayes extendido(clasificacion multiclase)\n",
    "     - Evaluacion y ajuste de rendimiento\n",
    "     - Validacion final\n",
    "       \n",
    "## 1. Generación del algoritmo de tratamiento de datos y representación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3d2c08-6422-4ca5-af55-cd9f9e173488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abierto</th>\n",
       "      <th>abrir</th>\n",
       "      <th>acceder</th>\n",
       "      <th>adicional</th>\n",
       "      <th>adiós</th>\n",
       "      <th>alguien</th>\n",
       "      <th>apertura</th>\n",
       "      <th>aplicación</th>\n",
       "      <th>atención</th>\n",
       "      <th>atender</th>\n",
       "      <th>...</th>\n",
       "      <th>urgente</th>\n",
       "      <th>usado</th>\n",
       "      <th>ver</th>\n",
       "      <th>visitar</th>\n",
       "      <th>vuelta</th>\n",
       "      <th>válido</th>\n",
       "      <th>whatsapp</th>\n",
       "      <th>yo</th>\n",
       "      <th>él</th>\n",
       "      <th>Clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saludo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saludo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saludo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saludo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Saludo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abierto  abrir  acceder  adicional  adiós  alguien  apertura  aplicación  \\\n",
       "0        0      0        0          0      0        0         0           0   \n",
       "1        0      0        0          0      0        0         0           0   \n",
       "2        0      0        0          0      0        0         0           0   \n",
       "3        0      0        0          0      0        0         0           0   \n",
       "4        0      0        0          0      0        0         0           0   \n",
       "\n",
       "   atención  atender  ...  urgente  usado  ver  visitar  vuelta  válido  \\\n",
       "0         0        0  ...        0      0    0        0       0       0   \n",
       "1         0        0  ...        0      0    0        0       0       0   \n",
       "2         0        0  ...        0      0    0        0       0       0   \n",
       "3         0        0  ...        0      0    0        0       0       0   \n",
       "4         0        0  ...        0      0    0        0       0       0   \n",
       "\n",
       "   whatsapp  yo  él   Clase  \n",
       "0         0   0   0  Saludo  \n",
       "1         0   0   0  Saludo  \n",
       "2         0   0   0  Saludo  \n",
       "3         0   0   0  Saludo  \n",
       "4         0   1   0  Saludo  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "diccionario = {\n",
    "    \"Saludo\": [\"Hola\", \"Buenos días\", \"Buenas tardes\", \"¿Cómo estás?\", \"Hola, ¿cómo están?\", \n",
    "               \"Muy buenos días, ¿pueden ayudarme?\", \"Buenas tardes, necesito información.\", \n",
    "               \"Hola, ¿hay alguien disponible?\", \"¡Saludos!\", \"¿Qué tal?\", \"¡Qué tal todo!\", \n",
    "               \"¡Hola, espero que estén bien!\", \"¡Buenos días! ¿Qué tal todo?\", \"¡Buenas tardes! ¿Cómo puedo ayudarte?\", \n",
    "               \"Hola, ¿qué tal todo por ahí?\"],\n",
    "    \"Queja\": [\"Quisiera hacer una queja\", \"No estoy satisfecho con el servicio\", \"El producto llegó dañado\", \n",
    "              \"No me ha gustado la atención recibida\", \"El servicio fue muy lento\", \"La calidad del producto no es buena\",\n",
    "              \"Estoy insatisfecho con lo que recibí\", \"El envío fue demorado\", \"No estoy contento con la compra\", \n",
    "              \"El producto no cumplió con mis expectativas\", \"El servicio no fue como esperaba\", \"Me siento decepcionado con la compra\"],\n",
    "    \"Reclamo\": [\"Necesito reclamar por un error\", \"Quiero hacer un reclamo\", \"Esto es inaceptable, quiero una solución\",\n",
    "                \"Estoy muy molesto, necesito hacer un reclamo.\", \"Quiero reportar un error con mi pedido.\",\n",
    "                \"Esto no cumple con lo que prometieron, quiero una solución.\", \"El producto no funciona, ¿cómo hago un reclamo?\",\n",
    "                \"Quiero mi dinero de vuelta, el producto llegó en mal estado.\", \"Esto es un error grave, necesito ayuda.\",\n",
    "                \"No me han respondido a tiempo, quiero hacer un reclamo\", \"Este problema es urgente, necesito que lo resuelvan ya\", \n",
    "                \"Mi producto no funciona, quiero saber qué hacer\"],\n",
    "    \"Petición\": [\"Me gustaría pedir información\", \"Necesito saber más detalles sobre el producto\", \"Por favor, envíenme más información\", \n",
    "                 \"¿Pueden darme más detalles?\", \"Quisiera saber más sobre sus servicios\", \"Por favor, envíenme una cotización\", \n",
    "                 \"Me gustaría conocer las características del producto\", \"¿Podrían enviarme más información por correo?\", \n",
    "                 \"Estoy interesado en saber más\", \"¿Tienen algún catálogo de productos?\", \"¿Me pueden dar detalles adicionales?\", \n",
    "                 \"¿Cómo puedo obtener más información sobre lo que ofrecen?\"],\n",
    "    \"Despedida\": [\"Adiós\", \"Hasta luego\", \"Nos vemos\", \"chao\", \"hasta pronto\", \"gracias\", \"Cuídate\", \"Hasta la próxima\", \n",
    "                  \"Que tengas un buen día\", \"Nos vemos pronto\", \"Hasta entonces\", \"Gracias por todo\", \"Me voy, adiós\", \n",
    "                  \"Hasta pronto, que estés bien\", \"Cuidate, nos vemos\"],\n",
    "    \"Información de contacto\": [\"¿Cómo puedo contactarlos?\", \"¿Cuál es el número de teléfono?\", \"¿Tienen un número de WhatsApp?\", \n",
    "                               \"¿Cuál es su correo electrónico?\", \"¿Cómo me comunico con el soporte?\", \"¿Tienen atención telefónica?\", \n",
    "                               \"¿Dónde los puedo ubicar?\", \"¿Puedo contactarlos por chat?\", \"¿Tienen un formulario de contacto?\", \n",
    "                               \"¿Dónde puedo encontrar información de contacto?\", \"¿Puedo llamarlos para soporte?\", \"¿Tienen línea directa?\"],\n",
    "    \"Horario de atención\": [\"¿Cuál es el horario de atención?\", \"¿En qué días están abiertos?\", \"¿A qué hora abren?\", \n",
    "                            \"¿Cuáles son los horarios para atención al cliente?\", \"¿Tienen horarios especiales?\", \n",
    "                            \"¿Puedo visitar la tienda en fin de semana?\", \"¿Abren los domingos?\", \"¿Cuál es el horario de apertura?\", \n",
    "                            \"¿Hasta qué hora están abiertos?\", \"¿Qué días atienden?\", \"¿El horario es el mismo todos los días?\", \n",
    "                            \"¿Puedo hacer una llamada fuera del horario habitual?\"],\n",
    "    \"Precios\": [\"¿Cuánto cuesta el producto?\", \"¿Cuál es el precio de servicio?\", \"¿Cuánto cuesta este producto?\", \n",
    "                \"¿Podrían decirme el precio del servicio?\", \"¿Hay descuentos disponibles?\", \"¿Es este el precio final o tiene impuestos adicionales?\", \n",
    "                \"Necesito saber los costos antes de decidirme.\", \"¿El precio incluye envío?\", \"¿Tienen precios para empresas?\", \n",
    "                \"¿Ofrecen planes de pago?\", \"¿Este precio es válido para todos los productos?\", \"¿El precio cambia según la cantidad?\"],\n",
    "    \"Política de devolución\": [\"¿Cuál es la política de devoluciones?\", \"¿Puedo devolver el producto?\", \"¿Hasta cuándo puedo devolverlo?\", \n",
    "                               \"¿Cuáles son los requisitos para una devolución?\", \"¿Tengo que pagar por el envío de la devolución?\", \n",
    "                               \"¿Puedo cambiar un producto?\", \"¿Cómo proceso una devolución?\", \"¿Puedo devolverlo si está usado?\", \n",
    "                               \"¿Cuánto tiempo tarda el reembolso?\", \"¿Qué debo hacer si el producto llega defectuoso?\", \"¿Puedo devolverlo en la tienda?\"],\n",
    "    \"Soporte técnico\": [\"Tengo un problema técnico\", \"¿Cómo puedo solucionar un error?\", \"Tengo un problema con el producto, ¿pueden ayudarme?\", \n",
    "                        \"¿Cómo resuelvo un error en el sistema?\", \"No sé cómo instalarlo, ¿me pueden dar soporte técnico?\", \"El dispositivo no enciende, ¿qué puedo hacer?\", \n",
    "                        \"Hay un fallo recurrente en mi aplicación, necesito ayuda.\", \"El sistema se cae, ¿cómo lo soluciono?\", \"¿Me pueden ayudar con la configuración?\", \n",
    "                        \"Mi dispositivo no funciona, ¿qué debo hacer?\", \"No puedo acceder a mi cuenta, ¿pueden ayudarme?\", \"¿Cómo restauro el sistema?\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Cargar el modelo de idioma español de spaCy\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "#SPACY PARA TOKENIZAR, LIMPIAR, LEMATIZAR Y ELIMINAR STOPWORDS\n",
    "def transformar_frase(frase):\n",
    "    doc = nlp(frase)  \n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "#DEVUELVE UN ARREGLO PLANO CON CADA UNA DE LAS FRASES DENTRO DE LOS VALUES.    \n",
    "for categoria, frases in diccionario.items():\n",
    "    for frase in frases:\n",
    "        texto_procesado = transformar_frase(frase)\n",
    "        data.append([texto_procesado, categoria])\n",
    "\n",
    "data = np.array(data)\n",
    "# print(data)\n",
    "df = pd.DataFrame(data, columns=[\"Texto transformado\", \"Clase\"])\n",
    "vacios= df[df['Texto transformado']=='']['Texto transformado'].index.tolist()\n",
    "df.drop(vacios,axis=0,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "# CREAMOS EL VECTORIZADOR PARA LA BOLSA DE PALABRAS\n",
    "vectorizer = CountVectorizer() \n",
    "\n",
    "# ALIMENTAR EL VECTORIZADOR Y CONVERTIR LA LISTA DE PALABRAS EN UNA MATRIZ DE FRECUENCIAS (BOLSA DE PALABRAS)\n",
    "bagwords=vectorizer.fit_transform(df['Texto transformado']).toarray()\n",
    "\n",
    "# CREAR EL DATAFRAME\n",
    "df_bagword = pd.DataFrame(bagwords, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# SE AGREGA LA COLUMNA DE ETIQUETAS\n",
    "df_bagword['Clase'] = df['Clase']\n",
    "\n",
    "df_bagword.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abb7a5-16eb-4345-8e9e-8f7709e34f94",
   "metadata": {},
   "source": [
    "## 2. VERIFICACIÓN DE LAS ETIQUETAS\n",
    "Debido a que en el paso 1 se efectuo paralelamente la union de las etiquetas con e conjunto de caracteristicas, este paso se precisa de una verificación de que todas las clases se hayan relacionado correctamente, inspeccionando el resumen de valores en la columna \"Clase\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6def9fd2-3638-4eef-9780-6c22d4d6ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clase\n",
       "Queja                      12\n",
       "Reclamo                    12\n",
       "Horario de atención        12\n",
       "Petición                   12\n",
       "Despedida                  12\n",
       "Información de contacto    12\n",
       "Soporte técnico            12\n",
       "Precios                    12\n",
       "Saludo                     11\n",
       "Política de devolución     11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bagword['Clase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89055c32-43a3-4c67-a832-434330818a32",
   "metadata": {},
   "source": [
    "## 3. APLICACIÓN DEL MODELO DE MACHINE LEARNING (REGRESIÓN LOGÍSTICA) \n",
    "Se desea aplicar un modelo multiclase naturalmente categorico, que proporcionara las prestaciones adecuadas para llevar a cabo la estimación. Se configura a continuacion el modelo haciendo uso de una evaluacion basica de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cff0d4-cd7d-451a-8844-2265dbda5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  ['Precios' 'Despedida' 'Información de contacto' 'Soporte técnico'\n",
      " 'Horario de atención' 'Petición' 'Reclamo' 'Política de devolución'\n",
      " 'Saludo' 'Queja'] \n",
      "\n",
      "train:  ['Información de contacto' 'Política de devolución' 'Petición' 'Precios'\n",
      " 'Soporte técnico' 'Reclamo' 'Despedida' 'Saludo' 'Queja'\n",
      " 'Horario de atención']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "x= df_bagword.drop(['Clase'],axis=1)\n",
    "y= df_bagword['Clase']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "print('test: ',y_test.unique(),'\\n')\n",
    "print('train: ',y_train.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987208b1-b148-4ed6-acf5-40093aafbbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "              Despedida       0.43      1.00      0.60         3\n",
      "    Horario de atención       1.00      0.75      0.86         4\n",
      "Información de contacto       1.00      0.67      0.80         3\n",
      "               Petición       0.50      1.00      0.67         1\n",
      " Política de devolución       1.00      0.80      0.89         5\n",
      "                Precios       1.00      1.00      1.00         2\n",
      "                  Queja       0.00      0.00      0.00         1\n",
      "                Reclamo       0.33      1.00      0.50         1\n",
      "                 Saludo       0.00      0.00      0.00         1\n",
      "        Soporte técnico       0.00      0.00      0.00         3\n",
      "\n",
      "               accuracy                           0.67        24\n",
      "              macro avg       0.53      0.62      0.53        24\n",
      "           weighted avg       0.67      0.67      0.63        24\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3 0 0 0 0 0 0 0 0 0]\n",
      " [1 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 4 0 1 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 2 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "90 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.38245614 0.27602339 0.09590643        nan 0.38245614 0.27602339\n",
      " 0.09590643        nan 0.38245614 0.27602339 0.09590643        nan\n",
      " 0.38245614 0.27602339 0.09590643        nan 0.38245614 0.27602339\n",
      " 0.09590643        nan 0.38245614 0.27602339 0.09590643        nan\n",
      " 0.45672515 0.38245614 0.09590643        nan 0.45672515 0.38245614\n",
      " 0.09590643        nan 0.45672515 0.38245614 0.09590643        nan\n",
      " 0.60584795 0.60584795 0.40409357        nan 0.60584795 0.60584795\n",
      " 0.40409357        nan 0.60584795 0.60584795 0.40409357        nan\n",
      " 0.62690058 0.60584795 0.55263158        nan 0.62690058 0.60584795\n",
      " 0.55263158        nan 0.62690058 0.60584795 0.55263158        nan\n",
      " 0.60643275 0.59532164 0.57426901        nan 0.60643275 0.59532164\n",
      " 0.57426901        nan 0.60643275 0.59532164 0.57426901        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Algoritmos de optimización\n",
    "    'max_iter': [100, 500, 1000],  # Número máximo de iteraciones\n",
    "    'penalty': ['l2', 'l1'],  # Tipo de regularización\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Definir GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajustar el modelo con los mejores parámetros encontrados\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "\n",
    "# Predecir con el modelo ajustado\n",
    "best_model = grid_search.best_estimator_\n",
    "prediccion = best_model.predict(x_test)\n",
    "\n",
    "# Métricas de evaluación\n",
    "\n",
    "### VALIDACIÓN DE SUB Y SOBRE AJUSTE ###\n",
    "y_train_pred = best_model.predict(x_train)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "y_test_pred = best_model.predict(x_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "### EVALUACIÓN ###\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, prediccion))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, prediccion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab9eb9-e99b-4458-a135-444e839efcc4",
   "metadata": {},
   "source": [
    "# 4. CONSTRUIR EL PIPELINE DE CONSUMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac45122-9ee7-4f57-9805-a71b9ac95eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Cargar el modelo de idioma español de spaCy\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "#SPACY PARA TOKENIZAR, LIMPIAR, LEMATIZAR Y ELIMINAR STOPWORDS\n",
    "def transformar_frase(frase):\n",
    "    doc = nlp(frase)  \n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "\n",
    "def agregar_pregunta(pregunta):\n",
    "    \n",
    "    pregunta_procesada = transformar_frase(pregunta)\n",
    "   \n",
    "    pregunta_bagword = vectorizer.transform([pregunta_procesada]).toarray()\n",
    "    prediccion = best_model.predict(pregunta_bagword)\n",
    "    print(f\"La clase predicha para la pregunta es: {prediccion[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5632ba2-ea4d-4350-9236-957d4546b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nueva_pregunta = input(\"Ingresa una nueva pregunta para predecir: \")\n",
    "agregar_pregunta(nueva_pregunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a695c9-7462-4636-8c9d-885bed4b5649",
   "metadata": {},
   "source": [
    "El modelo de lenguaje natural no tiene un rendimiento maximo, pero sin embargo tiene una exactitud del 100% dentro del conjunto de datos de entrenamiento y un 60% de exactitud para datos nuevos. Para efectos practicos el rendimiento es suficiente ya que necesitara de mayor cantidad de datos interpretativos de cada clase para poder optimizar sus respuestas. La calidad y cantidad de datos es importante, sin embargo existen factores ajustables como el tipo de modelo, los hiperparametros y el preprocesamiento del conjunto de entrenamiento que deberan considerarse para maximizar las prestaciones del sistema de predicción.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a1b00-baed-49dc-95c1-70dfff02327f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
